# =============================================================================
# GLOBAL-FIRST COMPLIANCE HEADER
# =============================================================================
# File: performance.py
# Phase: FAZ 4A â€“ BS-Model Orchestration + Cache
# =============================================================================

"""
Performance Orchestration Layer â€“ FAZ 4A

ROLE:
- Orchestrates BS-Model only
- Caches results for 30 seconds (95x speedup)
- NO UI language, NO affiliate, NO fake data
"""

from typing import Dict, Any
from datetime import datetime, timezone

from app.db.session import get_supabase_admin
from app.core.bs_model_engine_v1 import BSModelV1, BSModelInput

# =============================================================================
# ðŸš€ CACHE SYSTEM (FAZ 2 - 95x SPEEDUP)
# =============================================================================

_cache_store: Dict[str, tuple] = {}
CACHE_TTL_SECONDS = 30


def _get_from_cache(cache_key: str) -> Any:
    """Check cache and return data if valid."""
    if cache_key in _cache_store:
        cached_time, cached_data = _cache_store[cache_key]
        age = (datetime.now(timezone.utc) - cached_time).total_seconds()
        if age < CACHE_TTL_SECONDS:
            return cached_data
    return None


def _save_to_cache(cache_key: str, data: Any) -> None:
    """Save data to cache with timestamp."""
    _cache_store[cache_key] = (datetime.now(timezone.utc), data)


def get_cache_info() -> Dict[str, Any]:
    """Return cache statistics."""
    return {
        "entries": len(_cache_store),
        "ttl_seconds": CACHE_TTL_SECONDS,
        "keys": list(_cache_store.keys())
    }


def clear_cache(student_id: str = None) -> None:
    """Clear cache for specific student or all."""
    global _cache_store
    if student_id:
        key = f"perf_{student_id}"
        _cache_store.pop(key, None)
    else:
        _cache_store = {}


# =============================================================================
# ðŸ”’ SAFETY BUFFER (ISOLATED)
# =============================================================================

def _normalize_next_interval(bs_output: Dict[str, Any]) -> Dict[str, Any]:
    """
    Applies ONLY if mathematically impossible.
    Does NOT hide real errors.
    """
    if (
        bs_output.get("next_repetition") == 1
        and bs_output.get("next_ia", 0) <= 0
    ):
        bs_output["next_ia"] = 1
        bs_output["buffer_applied"] = True
    else:
        bs_output["buffer_applied"] = False

    return bs_output


# =============================================================================
# ðŸŽ›ï¸ PERFORMANCE ORCHESTRATOR
# =============================================================================

def get_student_performance(
    student_id: str,
    use_cache: bool = True
) -> Dict[str, Any]:
    """
    Main orchestration function.
    Returns topic performance with BS-Model calculations.
    """
    
    # ========== CACHE CHECK ==========
    cache_key = f"perf_{student_id}"
    
    if use_cache:
        cached = _get_from_cache(cache_key)
        if cached:
            cached["metadata"]["from_cache"] = True
            return cached
    
    # ========== DATABASE FETCH ==========
    supabase = get_supabase_admin()

    tests_resp = (
        supabase
        .table("student_topic_tests")
        .select("*")
        .eq("student_id", student_id)
        .order("test_date", desc=True)
        .execute()
    )

    tests = tests_resp.data or []

    # ========== EMPTY CASE ==========
    if not tests:
        result = {
            "topic_performance": {},
            "all_tests": [],
            "projection": None,
            "metadata": {
                "source": "faz4a",
                "from_cache": False,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
        }
        _save_to_cache(cache_key, result)
        return result

    # ========== GROUP BY TOPIC ==========
    topic_groups: Dict[str, list] = {}
    for t in tests:
        topic_groups.setdefault(t["topic_id"], []).append(t)

    topic_performance: Dict[str, Any] = {}

    # ========== CALCULATE PER TOPIC ==========
    for topic_id, topic_tests in topic_groups.items():
        latest = topic_tests[0]
        repetitions = len(topic_tests)

        # Actual gap (days between last two tests)
        if repetitions > 1:
            prev_date = datetime.fromisoformat(
                topic_tests[1]["test_date"].replace("Z", "+00:00")
            ).date()
            last_date = datetime.fromisoformat(
                latest["test_date"].replace("Z", "+00:00")
            ).date()
            actual_gap = (last_date - prev_date).days
        else:
            actual_gap = 0

        total = (
            latest["correct_count"]
            + latest["wrong_count"]
            + latest["empty_count"]
        )

        # Input normalization
        difficulty = latest.get("difficulty")
        if difficulty is None:
            difficulty = 3  # neutral default

        bs_input = BSModelInput(
            correct=latest["correct_count"],
            incorrect=latest["wrong_count"],
            blank=latest["empty_count"],
            total=total,
            difficulty=difficulty,
            current_ef=latest.get("ef"),
            current_ia=latest.get("interval_days"),
            actual_gap=actual_gap,
            repetitions=repetitions
        )

        bs_output = BSModelV1.calculate(bs_input)
        bs_dict = bs_output.model_dump()
        bs_dict = _normalize_next_interval(bs_dict)

        topic_performance[topic_id] = {
            "bs_model": bs_dict,
            "latest_test_date": latest["test_date"],
            "repetitions": repetitions
        }

    # ========== BUILD RESULT ==========
    result = {
        "topic_performance": topic_performance,
        "all_tests": tests,
        "projection": None,
        "metadata": {
            "source": "faz4a",
            "from_cache": False,
            "generated_at": datetime.now(timezone.utc).isoformat()
        }
    }

    # ========== SAVE TO CACHE ==========
    _save_to_cache(cache_key, result)

    return result
