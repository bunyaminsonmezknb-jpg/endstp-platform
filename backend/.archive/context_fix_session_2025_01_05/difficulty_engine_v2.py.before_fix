"""
Difficulty Engine v2.0.0 - CONTEXT-AWARE (CANLI ORGANÄ°ZMA)
Enriches v1 with archetype, prerequisites, and misconception matching

PHILOSOPHY:
- Consumes v1 difficulty (never changes score)
- Adds context-aware interpretation
- Archetype-based difficulty expectation
- Prerequisite health check
- Misconception pattern matching

DEPENDENCY: v1, Context Layer, Segmentation Engine

LOCK DATE: 2025-01-02
"""

from typing import Optional, Dict, List
from .difficulty_engine_v1 import DifficultyEngineV1, DifficultyInput, DifficultyConfig, DifficultyOutput


class DifficultyEngineV2:
    """Context-aware difficulty enrichment"""
    
    def __init__(self, context_service, segmentation_engine):
        self.v1_engine = DifficultyEngineV1()
        self.context_service = context_service
        self.segmentation_engine = segmentation_engine
    
    def calculate(
        self,
        input_data: DifficultyInput,
        student_id: str,
        config: Optional[DifficultyConfig] = None
    ) -> Dict:
        """
        Context-aware difficulty analysis
        
        Returns:
            {
                **v1_result,  # Base difficulty
                "archetype_context": {...},
                "prerequisite_health": {...},
                "misconception_matches": [...],
                "segment_context": {...}
            }
        """
        
        # 1. Get v1 baseline (never touch score)
        v1_result = self.v1_engine.calculate(input_data, config)
        
        # 2. Get student segment
        segment = self.segmentation_engine.get_level(student_id)
        
        # 3. Get topic context
        context = self.context_service.get_topic_context(input_data.topic_id)
        
        # 4. Archetype-based interpretation
        archetype_context = self._analyze_archetype_difficulty(
            context, v1_result, segment
        )
        
        # 5. Prerequisite health check
        prerequisite_health = self._check_prerequisite_health(
            input_data.topic_id, student_id
        )
        
        # 6. Misconception pattern matching
        misconception_matches = self._match_misconceptions(
            context, input_data
        )
        
        return {
            **v1_result.dict(),  # v1 untouched
            "archetype_context": archetype_context,
            "prerequisite_health": prerequisite_health,
            "misconception_matches": misconception_matches,
            "segment_context": {
                "level": segment["level"],
                "confidence": segment["confidence"]
            }
        }
    
    def _analyze_archetype_difficulty(
        self,
        context: Dict,
        v1_result: DifficultyOutput,
        segment: Dict
    ) -> Dict:
        """
        Archetype-based difficulty interpretation
        
        Foundational: LOW difficulty = CRITICAL (foundation must be solid)
        Synthesis: HIGH difficulty = EXPECTED (needs practice)
        """
        
        archetype = context.get("archetype", "foundational")
        
        interpretation = {
            "archetype": archetype,
            "expected_difficulty": "medium",
            "urgency": "MEDIUM",
            "note": None
        }
        
        if archetype == "foundational":
            # Foundational topics â†’ difficulty MUST be low
            if v1_result.difficulty_level in ["HIGH", "CRITICAL"]:
                interpretation.update({
                    "expected_difficulty": "low",
                    "urgency": "CRITICAL",
                    "note": "âš ï¸ TEMEL KONU! Zor bulman risk oluÅŸturur. Acil Ã§alÄ±ÅŸ."
                })
            else:
                interpretation.update({
                    "expected_difficulty": "low",
                    "urgency": "LOW",
                    "note": "âœ… Temel konu, durumun iyi."
                })
        
        elif archetype == "synthesis":
            # Synthesis topics â†’ difficulty expected
            if v1_result.difficulty_level in ["HIGH", "CRITICAL"]:
                interpretation.update({
                    "expected_difficulty": "medium-high",
                    "urgency": "MEDIUM",
                    "note": "ðŸ“ˆ Sentez konusu - zorluk normal. Pratik yaparak geliÅŸir."
                })
            else:
                interpretation.update({
                    "expected_difficulty": "medium-high",
                    "urgency": "LOW",
                    "note": "âœ… Sentez konusunda iyisin!"
                })
        
        return interpretation
    
    def _check_prerequisite_health(
        self,
        topic_id: str,
        student_id: str
    ) -> Dict:
        """
        Check if prerequisite topics are healthy
        """
        
        prerequisites = self.context_service.get_prerequisites(topic_id)
        
        if not prerequisites:
            return {
                "has_prerequisites": False,
                "weak_prerequisites": []
            }
        
        weak_prereqs = []
        
        for prereq in prerequisites:
            prereq_mastery = self._get_mastery(student_id, prereq["topic_id"])
            
            if prereq_mastery < 60:  # Threshold
                weak_prereqs.append({
                    "topic_id": prereq["topic_id"],
                    "topic_name": prereq.get("topic_name", "Unknown"),
                    "mastery": prereq_mastery,
                    "strength": prereq.get("strength", 0.5)
                })
        
        health_status = "HEALTHY"
        if len(weak_prereqs) >= len(prerequisites) * 0.5:
            health_status = "AT_RISK"
        elif weak_prereqs:
            health_status = "WEAK"
        
        recommendation = None
        if health_status != "HEALTHY":
            recommendation = (
                f"âš ï¸ {len(weak_prereqs)} Ã¶n koÅŸul konu zayÄ±f. "
                "Ã–nce temeli gÃ¼Ã§lendir."
            )
        
        return {
            "has_prerequisites": True,
            "total_prerequisites": len(prerequisites),
            "weak_prerequisites": weak_prereqs,
            "health_status": health_status,
            "recommendation": recommendation
        }
    
    def _match_misconceptions(
        self,
        context: Dict,
        input_data: DifficultyInput
    ) -> List[Dict]:
        """
        Match student errors to known misconceptions
        """
        
        misconceptions = context.get("misconceptions", [])
        
        if not misconceptions:
            return []
        
        # Simple heuristic: if wrong_rate > blank_rate
        wrong_rate = (
            input_data.questions_wrong / input_data.questions_total
            if input_data.questions_total > 0 else 0
        )
        blank_rate = (
            input_data.questions_blank / input_data.questions_total
            if input_data.questions_total > 0 else 0
        )
        
        matches = []
        
        # If wrong > blank â†’ likely misconception
        if wrong_rate > blank_rate and wrong_rate > 0.3:
            # Return top 2 most common misconceptions
            for misc in misconceptions[:2]:
                matches.append({
                    "pattern_tr": misc.get("pattern_tr", ""),
                    "correction_strategy": misc.get("correction_strategy", ""),
                    "confidence": "high" if wrong_rate > 0.5 else "medium"
                })
        
        return matches
    
    def _get_mastery(self, student_id: str, topic_id: str) -> float:
        """
        Get student mastery for a topic
        (Placeholder - will integrate with actual data)
        """
        # TODO: Integrate with actual mastery calculation
        # For now, return dummy value
        return 70.0  # Default